{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc48425a",
   "metadata": {},
   "source": [
    "Build a neural network to recognize different items of clothing, trained from a dataset containing 10 different types.\n",
    "The Fashion MNIST dataset is a collection of grayscale 28x28 pixel clothing images of 10 different types.This dataset is available directly in the tf.keras.datasets API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e409e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84353ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on unseen data\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dbe3ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the training and test split of the Fashion MNIST dataset\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13c2bb",
   "metadata": {},
   "source": [
    "Print a training image (both as an image and a numpy array), and a training label to see. Experiment with different indices in the array. For example, also take a look at index 42. That's a different boot than the one at index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6798e1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 2\n",
      "\n",
      "IMAGE PIXEL ARRAY:\n",
      " [[  0   0   0   0   0   1   1   0   0   0   0  63  28   0   0   0  33  85   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0  28 126 241 255 255 255 255 255 255 252 248 111   0   0   0   2   0   0   0   0]\n",
      " [  0   0   0   0   2   0   0 206 244 251 241 230 238 221 205 230 240 230 239 251 233 165   0   0   2   0   0   0]\n",
      " [  0   0   0   1   0   0 199 251 228 234 233 236 235 245 247 237 234 239 230 230 235 255 176   0   0   1   0   0]\n",
      " [  0   0   0   0   0  81 254 226 228 239 237 236 234 232 233 235 235 236 239 237 233 225 246  73   0   0   0   0]\n",
      " [  0   0   3   0   0 255 235 239 223 234 238 236 237 236 235 235 235 235 236 235 234 230 231 255  24   0   4   0]\n",
      " [  0   0   0   0 177 239 223 254 223 232 234 234 236 236 235 235 235 235 235 234 231 233 222 246  88   0   1   0]\n",
      " [  0   0   0   0 234 239 229 255 220 232 233 232 234 235 235 235 235 235 234 233 232 230 228 254 140   0   0   0]\n",
      " [  0   0   0   0 225 240 226 255 221 227 232 228 231 230 228 229 231 230 228 228 232 223 229 244 231   0   0   0]\n",
      " [  0   0   0  47 245 231 234 249 229 221 229 225 229 227 226 227 228 227 228 229 228 224 246 240 227   0   0   0]\n",
      " [  0   0   0  51 248 230 245 246 230 226 230 227 230 229 228 229 230 228 228 231 225 227 242 237 255   0   0   0]\n",
      " [  0   0   0 101 253 229 247 241 221 233 228 227 229 228 227 228 230 227 230 234 225 229 251 229 243  55   0   0]\n",
      " [  0   0   0 102 255 227 242 241 221 234 223 230 228 231 229 231 231 227 229 241 219 236 254 225 250 167   0   0]\n",
      " [  0   0   0  90 255 229 236 231 222 236 223 231 229 231 229 231 231 228 224 245 218 243 239 227 244 175   0   0]\n",
      " [  0   0   0 212 250 225 236 249 229 237 223 231 229 231 229 231 231 230 221 243 225 248 230 236 234 255   1   0]\n",
      " [  0   0   0 245 243 232 243 218 228 238 222 231 229 231 229 231 231 230 222 237 237 252 229 239 240 223   0   0]\n",
      " [  0   0  27 255 235 242 237 216 230 236 224 229 227 233 233 233 230 228 224 230 245 247 221 243 239 252   0   0]\n",
      " [  0   0  88 255 232 248 236 208 234 231 223 227 226 233 232 232 230 228 224 224 235 233 234 247 235 255   0   0]\n",
      " [  0   0  83 255 225 250 237 224 236 229 225 225 227 235 229 231 230 230 227 221 227 221 239 250 231 255   0   0]\n",
      " [  0   0  20 255 224 248 234 226 232 222 225 224 231 238 226 230 228 230 230 221 229 225 244 246 230 255   0   0]\n",
      " [  0   0  95 255 218 242 255 232 226 224 229 228 228 232 228 229 231 233 232 226 221 224 247 244 228 255   0   0]\n",
      " [  0   0 167 255 213 235 255  81 245 251 238 236 230 229 230 229 230 231 238 240 255 192 255 239 228 255  23   0]\n",
      " [  0   0 173 242 224 233 255   0 136 226 239 255 229 236 236 234 233 228 251 248 200  81 255 237 225 255 101   0]\n",
      " [  0   0 172 255 226 233 255   0   0   0   0   0   8  21  22  21  20  14   0   0   0   0 255 238 229 246 178   0]\n",
      " [  0   0  16 255 236 238 252   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 222 244 222 254 119   0]\n",
      " [  0   0   0  30 228 242 163   0   0   0   0   2   4   6   5   5   4   4   2   0   1   0 151 251 235 180   0   0]\n",
      " [  0   0   0   0 234 255 191   0  11   0   0   0   0   0   0   0   0   0   0   0   4   0 103 246 247  72   0   0]\n",
      " [  0   0   0   1  95  77  52   0   4   0   0   0   0   0   0   0   0   0   0   0   3   0  82 237 231  70   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x185da5f7e90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You can put between 0 to 59999 here\n",
    "index = 7\n",
    "\n",
    "# Set number of characters per row when printing\n",
    "np.set_printoptions(linewidth=320)\n",
    "\n",
    "# Print the label and image\n",
    "print(f'LABEL: {training_labels[index]}')\n",
    "print(f'\\nIMAGE PIXEL ARRAY:\\n {training_images[index]}')\n",
    "\n",
    "# Visualize the image\n",
    "plt.imshow(training_images[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a738930c",
   "metadata": {},
   "source": [
    "Above number are between 0 and 255. While training a neural network especially in image processing, for various reasons it will usually learn better if you scale all values to between 0 and 1. It's a process called normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac41f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values of the train and test images\n",
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635247b",
   "metadata": {},
   "source": [
    "# Design the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c864e98",
   "metadata": {},
   "source": [
    "Sequential: That defines a sequence of layers in the neural network.\n",
    "\n",
    "Flatten: Remember earlier where our images were a 28x28 pixel matrix when you printed them out? Flatten just takes that square and turns it into a 1-dimensional array.\n",
    "\n",
    "Dense: Adds a layer of neurons\n",
    "\n",
    "Each layer of neurons need an activation function to tell them what to do. There are a lot of options, one of them is:\n",
    "\n",
    "ReLU effectively means:\n",
    "\n",
    "if x > 0: \n",
    "  return x\n",
    "\n",
    "else: \n",
    "  return 0\n",
    "In other words, it only passes values greater than 0 to the next layer in the network.\n",
    "\n",
    "Softmax takes a list of values and scales these so the sum of all elements will be equal to 1. When applied to model outputs, you can think of the scaled values as the probability for that class. For example, in this classification model which has 10 units in the output dense layer, having the highest value at index = 4 means that the model is most confident that the input clothing image is a coat. If it is at index = 5, then it is a sandal, and so forth. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c5003",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa0ed5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the classification model\n",
    "#here 1st layer is input layer in the shape of data(28X28) and output layer in the shape of classes(10 different classes in dataset), Hidden layer with 128 neurons to find rules between them.\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),       \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2404390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input to softmax function: [[1. 3. 4. 2.]]\n",
      "output of softmax function: [[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
      "sum of outputs: 1.0\n",
      "class with highest probability: 2\n"
     ]
    }
   ],
   "source": [
    "#Declare sample inputs and convert to a tensor\n",
    "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "print(f'input to softmax function: {inputs.numpy()}')\n",
    "\n",
    "# Feed the inputs to a softmax activation function\n",
    "outputs = tf.keras.activations.softmax(inputs)\n",
    "print(f'output of softmax function: {outputs.numpy()}')\n",
    "\n",
    "# Get the sum of all values after the softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')\n",
    "\n",
    "# Get the index with highest value\n",
    "prediction = np.argmax(outputs)\n",
    "print(f'class with highest probability: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37c31e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7820 - loss: 0.6330\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8616 - loss: 0.3877\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8782 - loss: 0.3347\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8836 - loss: 0.3169\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8889 - loss: 0.2975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x185da89ff90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compile and train the model on training data and check accuracy\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec06ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3432\n",
      "Loss on test data: [0.3471408486366272, 0.8759999871253967]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on unseen data/test data to find loss\n",
    "loss = model.evaluate(test_images, test_labels)\n",
    "print(\"Loss on test data:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcf8da6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3432\n",
      "Accuracy on test data: 0.3471408486366272\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(test_images, test_labels)[0]  # Index 1 corresponds to accuracy if it's the second metric specified during model compilation\n",
    "print(\"Accuracy on test data:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa197137",
   "metadata": {},
   "source": [
    "# Test on various cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4580ce",
   "metadata": {},
   "source": [
    "compare classifications[0] (the model's prediction) with test_labels[0] (the true label), to understand how confident the model is in predicting the correct class for that particular image. The values in classifications[0] represent the model's confidence scores for each class, and the index with the highest score indicates the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7b85fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "[1.2998117e-05 2.2258466e-07 1.9106412e-07 5.5666569e-09 7.3515491e-07 3.7664950e-02 2.2218992e-06 7.6824710e-02 1.0595276e-05 8.8548344e-01]\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d44e63",
   "metadata": {},
   "source": [
    "In above the confidence for index 9 (index range : 0 to 9 ) is highest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4935b6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf29cab",
   "metadata": {},
   "source": [
    "In above test_labels[0] prints 9, it means that the first test image in the dataset belongs to class 9, which corresponds to the category \"Ankle boot\" in the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a95cf",
   "metadata": {},
   "source": [
    "# Adding more numbers of neurons in hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486fc2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 0.5987\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 0.3664\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 0.3199\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 0.2966\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 0.2775\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3354\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "0.3407962918281555\n",
      "[4.3708392e-06 1.9484925e-07 1.7647339e-07 2.8444740e-08 6.5339412e-07\n",
      " 3.3656455e-04 8.4988360e-06 9.0598166e-03 6.7618871e-06 9.9058294e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu), # Try experimenting with this layer\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "loss = model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "print(loss)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3600c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
